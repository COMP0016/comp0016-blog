<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="" />
    <meta name="author" content="Team 38" />
    <title>Implementation | WAPETS 2.0</title>

    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"
      crossorigin="anonymous"
    />

    <style>
      html,
      body {
        overflow-x: hidden; /* Prevent scroll on narrow devices */
      }

      @media (max-width: 991.98px) {
        .offcanvas-collapse {
          position: fixed;
          top: 56px; /* Height of navbar */
          bottom: 0;
          left: 100%;
          width: 100%;
          padding-right: 1rem;
          padding-left: 1rem;
          overflow-y: auto;
          visibility: hidden;
          background-color: #343a40;
          transition: transform 0.3s ease-in-out, visibility 0.3s ease-in-out;
        }
        .offcanvas-collapse.open {
          visibility: visible;
          transform: translateX(-100%);
        }
      }
    </style>
  </head>
  <body>
    <nav
      class="navbar navbar-expand-lg fixed-top navbar-dark bg-dark"
      aria-label="Main navigation"
    >
      <div class="container-fluid">
        <a class="navbar-brand" href="index.html" aria-current="page"
          >WAPETS 2.0</a
        >
        <button
          class="navbar-toggler p-0 border-0"
          type="button"
          id="navbarSideCollapse"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="navbar-collapse offcanvas-collapse">
          <ul class="navbar-nav me-auto mb-2 mb-lg-0">
            <li class="nav-item">
              <a class="nav-link active" href="01-requirements.html"
                >Requirements</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="02-hci.html">HCI</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="03-research.html">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="04-system-design.html"
                >System design</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="05-implementation.html"
                >Implementation</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="06-testing.html">Testing</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="07-evaluation.html"
                >Evaluation</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="08-appendix.html">Appendix</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <main class="container pt-5">
      <div class="row">
        <div class="col-md-8 offset-md-2">
          <h2 class="mt-3">Mobile App Implementation</h2>
          <div class="card mb-3">
            <div class="card-body">
              <h3 class="mt-3">AR Environment</h3>
              <p class="card-text">
                The app is written in C# on the Unity Android and iOS platform.
                It uses the popular ARCore and ARKit libraries for each platform
                respectively to interact with the camera environment on display.
              </p>
              <p class="card-text">
                The scene makes use of AR planes, both vertical and horizontal
                to map out the environment in the AR Viewport. Each plane is
                then judged on its walkability and enabled for ray-casting
              </p>
              <h3 class="mt-3">The Pet</h3>
              <p class="card-text">
                The app displays an anthropomorphic pet that can walk around the
                planes mapped by the AR Plane Manager object.
              </p>
              <p class="card-text">
                The Pet game object is composed of an Animator (in charge of
                controlling skeletal poses), a mesh/avatar (the 3D skinned mesh
                on display) and a Behaviour Script that allows the pet to walk
                around the AR viewport when in input is presented.
              </p>
              <p class="card-text">
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/ARPetRaycast.png"
                />
              </p>
              <p class="card-text">
                In addition to its input driven movement, the pet also tracks
                the user's location by turning to always face the camera.
              </p>
              <h3 class="mt-3">Voice Command Functionality</h3>
              <p class="card-text">
                Much like on the desktop version, the pet actively listens for
                voice commands using the phones microphone. Once a sentence is
                recorded, it is then transcribed into text using the IBM Cloud
                SDK's Speech-To-Text functionality. The text is scanned for
                available commands, a reply is selected, and an appropriate
                audio clip is generated by the SDK's Text-To-Speech module.
              </p>
              <h3 class="mt-3">The UI</h3>
              <p class="card-text">
                The user-interface is implemented as a collection of canvases
                and a UI manager. Each of the UI canvases has a main panel and a
                back button. There are canvases for the pets belonging to the
                user, settings, user information and accessories if available
                for the current pet.
              </p>
              <p class="card-text">
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/MobileUI.png"
                />
              </p>
              <h3 class="mt-3">Web API (C#)</h3>
              <p class="card-text">
                The API uses a .NET HttpClient to send and receive requests from
                the web server.
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/WebAPICode.png"
                />
              </p>
              <p class="card-text">
                Each request and response are formatted from JSON strings to C#
                structs and vice versa using Newtonsoft.Json. Requests are sent
                asynchronously, and responses are received asynchronously.
              </p>
              <p class="card-text">
                Each response is serialized into an APIResponse&lt;T&gt; generic
                structure that contains a T type payload and error code if the
                request was unsuccessful.
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/WebAPIResponse.png"
                />
              </p>
              <h3 class="mt-3">Functionality</h3>
              <p class="card-text">
                The web api has commands for all the functionality available
                from the Web Server.
              </p>

              <p class="card-text">
                It has both regular and Async versions of each request.
              </p>
              <p class="card-text">
                The api stores session information into a Session object which
                is then used to request data from the server..
              </p>
              <h3 class="mt-3">Documentation</h3>
              <p class="card-text">
                Documentation of the API is available on its GitHub repository
                README.
              </p>
              <h3 class="mt-3">Testing tools (Developer CLI)</h3>
              <p class="card-text">
                Together with the API is also packaged a command line tool that
                support executing commands on the web server directly
              </p>
              <p class="card-text">
                It was mainly used for managing pet data during development
                sessions
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/TestingCLI.png"
                />
              </p>
            </div>
          </div>
          <hr />

          <h2 class="mt-3">Desktop Assistant Implementation</h2>
          <div class="card mb-3">
            <div class="card-body">
              <h3 class="mt-3">Login</h3>
              <p class="card-text">
                The login screen sends and receives data from the web server
                when the user enters their login credentials. The login fails if
                the post request does not contain the user login information;
                otherwise, the user account information is verified and the
                SceneManager.LoadScene() method is used to load the
                application/GUI.
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/login.png"
                />
              </p>
              <h3 class="mt-3">Speech-to-text input</h3>
              <p class="card-text">
                The speech-to-text input works by the user’s microphone
                detecting the user’s speech input. This input is then sent by
                the STT (Speech to Text) manager to the Watson backend and
                retrieves the text string in response. The Assistant script then
                checks if the command is spoken and sends the text string to the
                chatbot. After receiving a response from the chatbot, the speech
                bubble shows up next to the pet. Meanwhile, the TTS (Text to
                Speech) sends the response text to the Watson backend, gets the
                audio clip in response to the user’s input, then plays the
                audio.
              </p>
              <h3 class="mt-3">Chatbot</h3>
              <p class="card-text">
                The chatbot is implemented using an open-source machine learning
                framework for automated text and voice-based communications
                software called Rasa. Rasa is a highly customisable,
                Python-based software that enables our project to interpret the
                input provided by the user in the form of speech-to-text and
                respond with the appropriate reply.
              </p>
              <h3 class="mt-3">Voice Control</h3>
              <p class="card-text">
                We implemented 2 types of voice commands in Unity.
              </p>
              <p class="card-text">
                The first are built-in Unity functions, like “play music” and
                “start timer”.
              </p>

              <p class="card-text">
                The second are external commands like “Open BBC”, “Search how to
                run”, etc. These commands can be customised by editing the
                configuration file under resources/configs folder. The app reads
                these commands from the config file and stores the commands in a
                dictionary.
              </p>
              <p class="card-text">
                Both methods use keyword detection. If the keyword is detected
                (after it is processed by IBM’s Watson Cloud SDK Speech-to-text
                function), the corresponding command is executed.
              </p>
              <h3 class="mt-3">Desktop Gadgets</h3>
              <p class="card-text">
                The desktop widgets include a music player with an autoscrolling
                bar, that is updated every frame by changing the x-y positions
                of the related GUI elements during each frame. The timer
                functions by calculating the time between the clicks on the
                start and stop buttons, while the real-time clock displays the
                time using Unity's Quaternion.Euler() methods to rotate the hour
                and minute hands.
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/auto_scroll.png"
                />
              </p>
              <h3 class="mt-3">Desktop Pet</h3>
              <p class="card-text">
                Our first implementation of the desktop pet was to have it look
                at the cursor. However, we scrapped this idea as the pet looking
                at the cursor was too weird and unnatural. We also tried
                changing the background as time-of-day changes – like stars
                during night, but we decided against it as its functionality was
                buggy and could cause some problems for people in different time
                zones. In our current implementation, the pet AI is essentially
                a state machine that reacts to different clicks. The OnDrag()
                method allows for the user to drag the pet across the screen,
                having the pet follow the mouse’s x-y coordinates on the screen
                plane to update the location of the virtual pet. The
                SwitchAnimation() method under the ReactToInteraction.cs script
                detects the input of the users mouse (left click, right click,
                scroll click or drag) to check whether the mouse is on the pet
                when it is clicked; if it is, then it redirectst the code to the
                appropriate pet interaction method and causes the pet to react
                accordingly.
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/clear_signal.png"
                />
              </p>
              <h3 class="mt-3">Some notes on Design Patterns</h3>
              <p class="card-text">
                We used the Singleton pattern for the WatsonManager and
                GameManager because we want them to be globally accessible and
                to be instantiated only once – they will not be destroyed upon
                entering the AR mode.
              </p>
              <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/singleton.png"
                />
              <p class="card-text">
                We used the Observer pattern for the SpeechBubble and
                TextToSpeech. This way, the Assistant sends a notification after
                receiving a response from the chatbot. After observing it, the
                SpeechBubble shows up and starts a timer.
              </p>
              <p class="card-text">
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/timer.png"
                />
              </p>
              <p class="card-text">
                When the timer reaches 0, the SpeechBubble disappears.
                TextToSpeech sends the text string to the backend, retrieves an
                audio clip, and plays it.
              </p>
              <p class="card-text">
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/observer.png"
                />
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/observer2.png"
                />
              </p>
            </div>
          </div>
          <hr />

          <h2 class="mt-3">Web Server</h2>
          <div class="card mt-3 mb-3">
            <div class="card-body">
              <h3 class="mt-3">Hosting</h3>
              <p class="card-text">
                The website is hosted on DigitalOcean App Platform, due to its
                speed of setup and continuous integration ability
              </p>
              <p class="card-text">
                Every time a commit is pushed to the master branch of the git
                repository, the website is redeployed (with automatic rollback
                if there is an issue with the deploy)
              </p>
              <p class="card-text">
                There is also a PostgreSQL database managed by DigitalOcean
              </p>
              <h3 class="mt-3">Web framework</h3>
              <p class="card-text">
                The code for the web server is written in Python, using the
                Django web framework
              </p>
              <p class="card-text">
                This is due to the range of features included in Django
                (including the ORM, and automated admin panel) as well as the
                wealth of libraries available for both Python and Django which
                make developing common patterns much easier
              </p>
              <p class="card-text">
                The ORM is used to manage the tables that store users and pets,
                and stably migrate database state when changes are made
              </p>
              <h3 class="mt-3">API</h3>
              <p class="card-text">
                The API is written using <b>djangorestframework</b> which sits
                on top of Django’s view system, to provide a set of common
                classes to do common API operations
              </p>
              <p class="card-text">
                The <b>ModelViewSet</b> provides the ability to create, read,
                list, update, and delete records in a database table (with the
                ability to add custom filters, for example the
                <b>PetViewSet</b> only shows pets for the current user)
              </p>
              <p class="card-text">
                The <b>Router</b> then links various URLS (/api/pet/3/update
                etc.) to their relevant views within the <b>ModelViewSet</b>
              </p>
              <p class="card-text">
                There is a <b>PetViewSet</b> which provides full CRUD for the
                <b>Pet</b> model
                <img
                  class="img img-fluid mb-3"
                  src="./assets/img/implementation/code_snippets/PetViewSet.png"
                />
              </p>
              <p class="card-text">
                There is <b>UserViewSet</b> which just provides an endpoint for
                the currently logged in user to get information about their
                account (name, preferences etc.)
              </p>
              <h3 class="mt-3">Authentication</h3>
              <p class="card-text">
                Uses JSON Web Tokens (JWT) which is an open standard for sending
                encryption and signatures as JSON
              </p>
              <p class="card-text">
                A user sends a username and password to an API endpoint and, if
                they match a user account in the system, they are returned a JWT
              </p>
              <p class="card-text">
                This JWT contains which account the user is authenticated to,
                along with the expiry date (1 week after obtaining), and a
                signature generated using a key stored on the server which
                verifies the enclosed information
              </p>
              <p class="card-text">
                This token should be included with every API request as a bearer
                token in the Authorization header.
              </p>
              <p class="card-text">
                This allows the server to know that the user is authenticated to
                access the API, and specifically which account they are
                authenticated to (so that the correct data can be returned)
              </p>
              <p class="card-text">
                The underlying implementation of this signing algorithm is done
                by a python library call <b>drf-jwt</b>
              </p>
              <h3 class="mt-3">Documentation</h3>
              <p class="card-text">
                There is API documentation provided as a hosted webpage,
                alongside the API
              </p>
              <p class="card-text">
                This is achieved using a few pieces of open-source technology
                connected together
              </p>
              <p class="card-text">
                <b>Swagger</b> is a system to describe API’s using JSON, in
                order to make them indexable by automated systems
              </p>
              <p class="card-text">
                There is a related project called <b>Swagger UI</b> which can
                take an API description in Swagger and create very detailed API
                documentation, including example requests and responses
              </p>
              <p class="card-text">
                Lastly, there is a library called <b>drf-yasg</b> which
                generates a Swagger description of a djangorestframework API
              </p>
              <p class="card-text">
                Combining drf-yasg and Swagger UI, we were able to generate very
                usable API documentation, with all of the definitions coming
                from the same code that actually implements the API. There was
                some amount of difficulty changing the default functionality of
                both drf-yasg and Swagger UI, to customise the documentation a
                bit, but this is to be expected.
              </p>
            </div>
          </div>
          <hr />
        </div>
      </div>

      <footer
        class="d-flex flex-wrap justify-content-between align-items-center py-3 my-4 border-top"
      >
        <p class="col-md-4 mb-0 text-muted">
          &copy;
          <script>
            document.write(new Date().getFullYear());
          </script>
          Team 38
        </p>

        <!--        <a href="/2021/group38" class="col-md-4 d-flex align-items-center justify-content-center mb-3 mb-md-0 me-md-auto link-dark text-decoration-none">-->
        <!--          <svg class="bi me-2" width="40" height="32"><use xlink:href="#bootstrap"/></svg>-->
        <!--        </a>-->

        <ul class="nav col-md-4 justify-content-end">
          <li class="nav-item">
            <a href="/2021/group38" class="nav-link px-2 text-muted">Home</a>
          </li>
        </ul>
      </footer>
    </main>

    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
      crossorigin="anonymous"
    ></script>

    <script>
      (function () {
        "use strict";

        document
          .querySelector("#navbarSideCollapse")
          .addEventListener("click", function () {
            document
              .querySelector(".offcanvas-collapse")
              .classList.toggle("open");
          });
      })();
    </script>
  </body>
</html>
